{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4643151f-8b64-40cb-9b36-758e369e6407",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bc9df7-5328-4945-a1bd-30f823fc8b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM,\n",
    "    TrainingArguments, Trainer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType, prepare_model_for_kbit_training\n",
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n",
    "import wandb\n",
    "import evaluate  # Hugging Face's evaluate library\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from bert_score import BERTScorer, score as bert_score\n",
    "\n",
    "from utils import tokenize_dataset_for_domain_bound_qna\n",
    "from prompt_templates import qna_prompt_template as prompt_template\n",
    "from generate import generate, stream_generate\n",
    "from evaluation_metrics import compute_metrics_for_qna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b458060f-cfcf-4f51-a6aa-506cef1dc7c1",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb057781-55b7-494f-bcb4-dd7d00ba4ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../models/phi_domain_bound_qna_finetuned_attempt_10/final\"\n",
    "\n",
    "data_path = \"../data/domain_bound_data/v7/\"\n",
    "test_data_path = data_path + \"test.csv\"\n",
    "\n",
    "model_id = \"microsoft/Phi-3.5-mini-instruct\"\n",
    "base_model_path = \"../models/phi_qna_finetuned_attempt_5/final_merged\"\n",
    "\n",
    "max_len = 512\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38a3746-3c13-42cc-920a-2614eeede918",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"domain_bound_qna_finetune-evaluation\", name=\"attempt_10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f573ca-73a8-4ef6-af46-ecd2d84e6bad",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15035ec-6729-4cf4-a946-1b1f2a700e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8443f97-858d-4220-b3d2-8f728fa48020",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac602a77-0a3a-4d89-915a-b102625ebce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_data_path)\n",
    "test_set = tokenize_dataset_for_domain_bound_qna(tokenizer, test_df, prompt_template, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d60d571-b664-464b-a3b5-7ba96d0e8e22",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4bbed1-cead-4893-980c-ab4269030a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cb96b6-5bd7-44d1-bd84-c6a107afddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Quantized model loading ===\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_path,\n",
    "    # quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afd719f-5e81-4335-82ad-c4346f9d2b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b63bf7-fe1b-401f-b8c1-a394a65ed24d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(model, model_path)\n",
    "model.eval() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0fd68d-392c-49c4-bc85-81c05bb4a07b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086ce6b4-018f-422f-a85e-285f9038dbbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1b39ed-ea6c-426c-a76c-63ac9283a909",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded167b3-4fc9-439c-8c3c-238d193c5a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9a3294-c17a-403d-9fe7-626608f6f6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./eval_output_base\",\n",
    "#     per_device_eval_batch_size=batch_size,\n",
    "#     do_eval=True,\n",
    "#     report_to=\"none\"\n",
    "# )\n",
    "\n",
    "# base_model_trainer = Trainer(\n",
    "#     model=base_model,\n",
    "#     args=training_args,\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "# )\n",
    "\n",
    "# base_model_eval_result = base_model_trainer.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6480b4-2485-422f-a289-898f0ba4dbe9",
   "metadata": {},
   "source": [
    "# Test set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f852223-0fa4-49c8-9f81-e600cef32e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./eval_output\",\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    do_eval=True,\n",
    "    report_to=\"none\",\n",
    "    eval_accumulation_steps=2,\n",
    "    label_names=[\"labels\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d93a44e-cf37-4dc0-8171-3bde13eaca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer, padding=False),\n",
    "    compute_metrics=lambda sample: compute_metrics_for_qna(sample, tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d3989f-7cbb-47aa-8197-c2dab6692fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Evaluate perplexity ===\n",
    "eval_result = trainer.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddcdbf5-5d13-49ac-b3a3-86e2986139ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print all results\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(f\"Loss: {eval_result['eval_loss']:.4f}\")\n",
    "print(f\"Perplexity: {torch.exp(torch.tensor(eval_result['eval_loss'])):.2f}\")\n",
    "print(f\"BLEU: {eval_result['eval_bleu']:.4f}\")\n",
    "print(f\"ROUGE-1: {eval_result['eval_rouge1']:.4f}\")\n",
    "print(f\"ROUGE-2: {eval_result['eval_rouge2']:.4f}\")\n",
    "print(f\"ROUGE-L: {eval_result['eval_rougeL']:.4f}\")\n",
    "print(f\"BERTscore precision: {eval_result['eval_bertscore_precision']:.4f}\")\n",
    "print(f\"BERTscore recall: {eval_result['eval_bertscore_recall']:.4f}\")\n",
    "print(f\"BERTscore f1: {eval_result['eval_bertscore_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92be58f3-423a-42b3-9bc4-ae8a46dc9351",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\n",
    "    \"eval_loss\": eval_result['eval_loss'], \n",
    "    \"perplexity\": torch.exp(torch.tensor(eval_result['eval_loss'])),\n",
    "    \"BLUE\": eval_result['eval_bleu'],\n",
    "    \"ROUGE_1\": eval_result['eval_rouge1'],\n",
    "    \"ROUGE_2\": eval_result['eval_rouge2'],\n",
    "    \"ROUGE_L\": eval_result['eval_rougeL'],\n",
    "    \"BERTscore_precision\": eval_result['eval_bertscore_precision'],\n",
    "    \"BERTscore recall\": eval_result['eval_bertscore_recall'],\n",
    "    \"BERTscore f1\": eval_result['eval_bertscore_f1']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b2230f-5ca1-4de9-a0c2-2be1f2b044cb",
   "metadata": {},
   "source": [
    "## Med / non-med classication evalution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8331d8-93e9-467f-ad52-aa1bd8b75917",
   "metadata": {},
   "source": [
    "How well the model idetifies the non med questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3effc07d-b965-4dd7-b48a-f1c6cc06b134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_class(sample):\n",
    "    predicted = generate(model, tokenizer, prompt_template.format(question=sample[\"question\"]), max_new_tokens=5).split(\"# Answer:\")[1].strip()\n",
    "    predicted_class = re.findall(r\"<.*>\", predicted)[0][1:-1]\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09b549c-3051-4b89-a4a1-5e95e013ef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"predicted_class\"] = test_df.apply(get_predicted_class, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67e192f-8035-4080-bc90-77d432bd6f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade1f434-c5bb-487a-ae17-b85ae96175a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = {\"med\": {\"med\": 0, \"non_med\": 0}, \"non_med\": {\"med\": 0, \"non_med\": 0}}\n",
    "correct_count = 0\n",
    "\n",
    "def update_confusion_matrix(sample):\n",
    "    global correct_count\n",
    "    confusion_matrix[sample[\"predicted_class\"]][sample[\"class\"]] += 1\n",
    "    if sample[\"predicted_class\"] != sample[\"class\"]:\n",
    "        print(sample[\"question\"])\n",
    "    else:\n",
    "        correct_count += 1\n",
    "    \n",
    "test_df.apply(update_confusion_matrix , axis=1)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4240b9-9fc3-443a-aa4a-1fec74a87230",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = correct_count / test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9f6303-130f-4bc1-b8fb-32f463ddcc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_med_precision = confusion_matrix[\"non_med\"][\"non_med\"] / (confusion_matrix[\"non_med\"][\"med\"] + confusion_matrix[\"non_med\"][\"non_med\"])\n",
    "non_med_recall = confusion_matrix[\"non_med\"][\"non_med\"] / (confusion_matrix[\"med\"][\"non_med\"] + confusion_matrix[\"non_med\"][\"non_med\"])\n",
    "med_precision = confusion_matrix[\"med\"][\"med\"] / (confusion_matrix[\"med\"][\"med\"] + confusion_matrix[\"med\"][\"non_med\"])\n",
    "med_recall = confusion_matrix[\"med\"][\"med\"] / (confusion_matrix[\"med\"][\"med\"] + confusion_matrix[\"non_med\"][\"med\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26f676a-e8b1-4591-878f-e437f9de8ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Non-med precision: {non_med_precision:.4f}\")\n",
    "print(f\"Non-med recall: {non_med_recall:.4f}\")\n",
    "print(f\"Med precision: {med_precision:.4f}\")\n",
    "print(f\"Med recall: {med_recall:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c73a936-bd43-444e-8946-b7ae04a3abcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\n",
    "    \"non_med_precision\": non_med_precision,\n",
    "    \"non_med_recall\": non_med_recall,\n",
    "    \"med_precision:\": med_precision,\n",
    "    \"med_recall\": med_recall,\n",
    "    \"accuracy\": accuracy\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7b6324-721a-40fd-94e8-260ae1f37420",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c50739-9375-48b4-b882-d90e32d26f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    \"What is Glaucoma ?\",\n",
    "    \"What are the symptoms of Glaucoma ?\",\n",
    "    \"My sister is on Xanax, feyntnol patch and a pain medicine for cancer.  She has been on 25 of fentynol and within 6 days she has been bumped up to 100 now she is almost lethargic and breathing is really labored and right arm is twitching.. She was carrying on conversation Sunday and Monday patch was put on Tuesday and now cant even sit up..no one seems worried but me.. Just wondering what I could do\",\n",
    "    \"I was playing basketball the other night and went up to block a shot and flipped over the guy and landed on my side/back. Since then the lower left side of back/side have been sore, hurts when I take deep breaths and when I lay on my back, any chance of a bruised kidney or any serious injury I could have?\",\n",
    "    \"What are the treatments for High Blood Pressure ?\",\n",
    "    \"What is (are) Urinary Tract Infections ?\",\n",
    "    \"Create a C++ function that computes the Fast Fourier Transform (FFT) of a signal\",\n",
    "    \"When did Beyonce start becoming popular?\",\n",
    "    \"What are the symptoms of diabetes ?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c88cd6b-f8c7-4061-95be-437c21efddaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(generate(model, tokenizer, prompt_template.format(question=examples[-3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f386f3f-2af8-4b44-a35b-903df2ffe216",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in stream_generate(model, tokenizer, prompt_template.format(question=\"Create a C++ function that computes the Fast Fourier Transform (FFT) of a signal\"), do_sample=False, max_new_tokens=512, skip_special_tokens=False):\n",
    "    print(token, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9063faa6-b569-4dfc-ba82-27f879bd23a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_table = wandb.Table(columns=[\"Question\", \"Generated answer\"])\n",
    "\n",
    "for example in examples:\n",
    "    generated_answer = \"\"\n",
    "    for token in stream_generate(model, tokenizer, prompt_template.format(question=example), do_sample=False):\n",
    "        generated_answer += token\n",
    "    wandb_table.add_data(example, generated_answer)\n",
    "    print(example, \"\\n\", generated_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5d7d3e-ad44-44f3-8925-e29fa4e223ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"generated_samples\": wandb_table})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
