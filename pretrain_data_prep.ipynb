{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66ccf3e2-3d7c-4c27-8bb6-8e69c75825ef",
   "metadata": {},
   "source": [
    "# Pretrain data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5557cf77-cf53-468f-83b2-4ab889de647f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e7ccd5-1fbe-4106-8f2b-b530e57986bf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "from ftplib import FTP\n",
    "import gzip\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "from datasets import load_dataset, Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39f165a-dd12-4a9f-8269-e3aa82853072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "ftp_host = \"ftp.ncbi.nlm.nih.gov\"\n",
    "ftp_dir = \"/pubmed/baseline\"\n",
    "download_dir = \"../data/pubmed_baseline\"\n",
    "max_files = 300  # ← Limit how many files to download\n",
    "\n",
    "gz_dir = download_dir\n",
    "min_words = 20  # Minimum number of words in abstract\n",
    "max_workers = 8  # Adjust based on your CPU\n",
    "output_csv = download_dir + \"/pubmed_filtered.csv\"\n",
    "output_csv_small = download_dir + \"/pubmed_filtered_small.csv\"\n",
    "train_csv = download_dir + \"/pubmed_train.csv\"\n",
    "test_csv = download_dir + \"/pubmed_test.csv\"\n",
    "val_csv = download_dir + \"/pubmed_val.csv\"\n",
    "train_tokenized = download_dir + \"/pubmed_train\"\n",
    "test_tokenized = download_dir + \"/pubmed_test\"\n",
    "val_tokenized = download_dir + \"/pubmed_val\"\n",
    "\n",
    "train_size = 1_000_000\n",
    "test_size = 3000\n",
    "val_size = 200\n",
    "\n",
    "max_len = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559fd489-9aeb-4a01-9845-52a747ff832c",
   "metadata": {},
   "source": [
    "### Download the pubmed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41420162-d4f3-48b5-b7a6-0e5d8ea75fec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "# Connect to FTP and list files\n",
    "ftp = FTP(ftp_host)\n",
    "ftp.login()\n",
    "ftp.cwd(ftp_dir)\n",
    "files = []\n",
    "ftp.retrlines(\"NLST\", files.append)\n",
    "ftp.quit()\n",
    "\n",
    "# Filter .gz files and limit number\n",
    "gz_files = sorted([f for f in files if f.endswith(\".gz\")])[:max_files]\n",
    "gz_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b1eab5-0c84-41e8-a0fe-de1d18882bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download\n",
    "base_url = f\"https://{ftp_host}{ftp_dir}/\"\n",
    "for fname in tqdm(gz_files):\n",
    "    # print(f\"Downloading: {fname}\")\n",
    "    url = base_url + fname\n",
    "    dest = os.path.join(download_dir, fname)\n",
    "    urlretrieve(url, dest)\n",
    "\n",
    "print(f\"\\n✅ Downloaded {len(gz_files)} files to `{download_dir}/`\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb00d06-9f34-4ee2-9b8f-8d01bbbd1e5d",
   "metadata": {},
   "source": [
    "# Process files in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9f7821-4f36-40f9-aeea-611f56154bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_words = 20\n",
    "max_workers = 4\n",
    "\n",
    "def parse_and_filter(file_path):\n",
    "    rows = []\n",
    "    try:\n",
    "        with gzip.open(file_path, 'rb') as f:\n",
    "            tree = ET.parse(f)\n",
    "        root = tree.getroot()\n",
    "        for article in root.findall(\".//PubmedArticle\"):\n",
    "            pmid = article.findtext(\".//PMID\")\n",
    "            lang = article.findtext(\".//Language\")\n",
    "            title = article.findtext(\".//ArticleTitle\")\n",
    "            abstract = article.findtext(\".//Abstract/AbstractText\")\n",
    "\n",
    "            if not (pmid and title and abstract):\n",
    "                continue\n",
    "            if lang and lang.strip().lower() != \"eng\":\n",
    "                continue\n",
    "            if len(abstract.split()) < min_words:\n",
    "                continue\n",
    "\n",
    "            rows.append((pmid.strip(), title.strip(), abstract.strip()))\n",
    "    except Exception as e:\n",
    "        print(f\"Error in {file_path}: {e}\")\n",
    "    return rows\n",
    "\n",
    "def process_files_in_chunks(gz_dir, output_csv, workers=4):\n",
    "    files = sorted([os.path.join(gz_dir, f) for f in os.listdir(gz_dir) if f.endswith(\".gz\")])\n",
    "\n",
    "    # Initialize CSV with header\n",
    "    with open(output_csv, \"w\", newline='', encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"pmid\", \"title\", \"abstract\"])\n",
    "\n",
    "    # Process files in parallel\n",
    "    with ProcessPoolExecutor(max_workers=workers) as executor:\n",
    "        futures = {executor.submit(parse_and_filter, f): f for f in files}\n",
    "        for future in as_completed(futures):\n",
    "            rows = future.result()\n",
    "            if rows:\n",
    "                with open(output_csv, \"a\", newline='', encoding=\"utf-8\") as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerows(rows)\n",
    "\n",
    "# Run it\n",
    "process_files_in_chunks(gz_dir, output_csv, workers=max_workers)\n",
    "print(f\"\\n✅ Data written incrementally to: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0ccf13-fed7-422f-8410-a8487dea5cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8972f7b1-69cf-42d0-821f-6998bbc90e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2cbb35-d90b-4a42-bce0-39f3b214e169",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377d0608-52e3-4e92-a3ea-3b6534bec9e3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = df.loc[:train_size -1, :]\n",
    "test_df = df.loc[train_size:train_size + test_size - 1, :]\n",
    "val_df = df.loc[train_size + test_size: train_size + test_size + val_size - 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba38313-2f92-4b22-9e8a-794516e0cbd3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.shape, test_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c005ae26-bda7-43fc-b94e-e35e7cc0d57f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.to_csv(train_csv, index=False)\n",
    "test_df.to_csv(test_csv, index=False)\n",
    "val_df.to_csv(val_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efea6c32-6a5c-4b9a-a738-a13e5400216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54425f52-4e4b-4c81-8e01-498b57f58c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_id = \"microsoft/Phi-3.5-mini-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bad7ff-0846-4219-b5f2-028b8d0cddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_csv).iloc[:200_001, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149c981b-abaa-4cf6-84b7-4e5cfdce7fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_token_count(example):\n",
    "    text = f\"{example['title']}\\n{example['abstract']}{tokenizer.eos_token}\"\n",
    "    return len(tokenizer(text, truncation=False)[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87b82cd-0b94-4ce4-9c9b-173d5e2bdd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"n_tokens\"] = train_df.apply(calculate_token_count, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb35dbd-76e1-450c-b9ad-a78af5e3d8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464a626b-9901-430d-a0c4-794ef69a8eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"n_tokens\"].apply(lambda x: min(300, x)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d246588-80b5-4ea9-9959-71b562cf7806",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.iloc[8, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9732a0-e7a4-4748-bfdf-8ec1a44385a0",
   "metadata": {},
   "source": [
    "total training tokens count = 48_931_561"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
