{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedd5ae7-e718-4db9-9b4a-ff81be0e2457",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install absl-py rouge-score nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034bab24-dc8a-4b83-a570-29fcf3bdeada",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m nltk.downloader punkt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4643151f-8b64-40cb-9b36-758e369e6407",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bc9df7-5328-4945-a1bd-30f823fc8b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM,\n",
    "    TrainingArguments, Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType, prepare_model_for_kbit_training\n",
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from evaluation_metrics import compute_metrics_for_pretrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b458060f-cfcf-4f51-a6aa-506cef1dc7c1",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb057781-55b7-494f-bcb4-dd7d00ba4ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../models/phi_pubmed_pretrained_attempt_5/final\"\n",
    "\n",
    "data_path = \"../data/pubmed_baseline/\"\n",
    "test_data_path = data_path + \"pubmed_test.csv\"\n",
    "\n",
    "model_id = \"microsoft/Phi-3.5-mini-instruct\"\n",
    "\n",
    "max_len = 360\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f573ca-73a8-4ef6-af46-ecd2d84e6bad",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8443f97-858d-4220-b3d2-8f728fa48020",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9145ea-6249-4c60-b086-14025a1ee4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset(tokenizer, data_df):\n",
    "    dataset = Dataset.from_pandas(data_df)\n",
    "    def tokenize(example):\n",
    "        text = f\"<s>{example['title']}\\n{example['abstract']}</s>\"\n",
    "        return tokenizer(text, truncation=True, padding=\"max_length\", max_length=max_len, return_attention_mask=True)\n",
    "    dataset = dataset.map(tokenize, batched=False)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac602a77-0a3a-4d89-915a-b102625ebce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "test_set = tokenize_dataset(tokenizer, test_df.iloc[:2000, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d60d571-b664-464b-a3b5-7ba96d0e8e22",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cb96b6-5bd7-44d1-bd84-c6a107afddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Quantized model loading ===\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    # quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b63bf7-fe1b-401f-b8c1-a394a65ed24d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(model, model_path)\n",
    "model.eval() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0fd68d-392c-49c4-bc85-81c05bb4a07b",
   "metadata": {},
   "source": [
    "### Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded167b3-4fc9-439c-8c3c-238d193c5a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY FOR base model evaluation\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6480b4-2485-422f-a289-898f0ba4dbe9",
   "metadata": {},
   "source": [
    "# Test set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38a3746-3c13-42cc-920a-2614eeede918",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"pubmed-pretrain-evaluation\", name=\"attempt_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f852223-0fa4-49c8-9f81-e600cef32e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./eval_output\",\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    do_eval=True,\n",
    "    report_to=\"none\",\n",
    "    eval_accumulation_steps=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d93a44e-cf37-4dc0-8171-3bde13eaca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    "    compute_metrics=compute_metrics_for_pretrain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d3989f-7cbb-47aa-8197-c2dab6692fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = trainer.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddcdbf5-5d13-49ac-b3a3-86e2986139ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all results\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(f\"Loss: {eval_result['eval_loss']:.4f}\")\n",
    "print(f\"Perplexity: {torch.exp(torch.tensor(eval_result['eval_loss'])):.2f}\")\n",
    "print(f\"BLEU: {eval_result['eval_bleu']:.4f}\")\n",
    "print(f\"ROUGE-1: {eval_result['eval_rouge1']:.4f}\")\n",
    "print(f\"ROUGE-2: {eval_result['eval_rouge2']:.4f}\")\n",
    "print(f\"ROUGE-L: {eval_result['eval_rougeL']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92be58f3-423a-42b3-9bc4-ae8a46dc9351",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\n",
    "    \"eval_loss\": eval_result['eval_loss'], \n",
    "    \"perplexity\": torch.exp(torch.tensor(eval_result['eval_loss'])),\n",
    "    \"BLUE\": eval_result['eval_bleu'],\n",
    "    \"ROUGE_1\": eval_result['eval_rouge1'],\n",
    "    \"ROUGE_2\": eval_result['eval_rouge2'],\n",
    "    \"ROUGE_L\": eval_result['eval_rougeL']    \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7b6324-721a-40fd-94e8-260ae1f37420",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14185bf3-943b-4a05-b9e0-649841a4723a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, text, max_new_tokens=128):\n",
    "    sample = tokenizer(text, truncation=True, padding=False, max_length=max_len, return_attention_mask=True)\n",
    "    input_ids = torch.tensor([sample[\"input_ids\"]]).to(model.device)\n",
    "    attention_mask = torch.tensor([sample[\"attention_mask\"]]).to(model.device)\n",
    "    \n",
    "    generated_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=False,\n",
    "        use_cache=False\n",
    "    )\n",
    "    \n",
    "    generated_texts = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "    return generated_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f748a1-4da5-439e-911d-0c76f22bbedc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generated_text = generate(model, \"The relationship between diabetes and blood pressure\\n\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e867378a-e7b3-4674-ba2a-0adccf82ffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"example_1\": generated_text})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
